# SyntheticData

Getting access to good data for model development and testing is almost always a challenge especially when the data is sensitive or includes personally identifiable information (PII).  Attempts to preserve privacy through anonymization techniques such as hashing, masking, and even noise obfuscation are sometimes insufficient.  The [attack on the Netflix Prize dataset](https://arvix.org/pdf/cs/0610105.pdf) and studies looking at [limitations of current methods used for protecting health care data](https://www.semanticscholar.org/paper/Practicing-Differential-Privacy-in-Health-Care%3A-A-Dankar-Emam/65a537c9cd327c2925676f59ddffa01cf4afbe51) demonstrate just how difficult privacy preservation is.  Even when sensitive and/or identifying variables are removed from the dataset, other variables can act as identifiers when they are combined.

Despite being around for a long time, synthetic data is enjoying a renaissance given the ever-growing need for realistic data.  As synthetic data is algorithmically generated with machine learning techniques, it is never directly based on actual real events or individuals, and hence ensuring a high degree of privacy.